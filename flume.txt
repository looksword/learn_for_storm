




1）.数据采集
负责从各节点上实时采集数据，选用cloudera的flume来实现
2）.数据接入
由于采集数据的速度和数据处理的速度不一定同步，因此添加一个消息中间件来作为缓冲，选用apache的kafka
3）.流式计算
对采集到的数据进行实时分析，选用apache的storm
4）.数据输出
对分析后的结果持久化，暂定用mysql
另一方面是模块化之后，假如当Storm挂掉了之后，
数据采集和数据接入还是继续在跑着，数据不会丢失，storm起来之后可以继续进行流式计算；





Kafka集群：Kafka是一种高吞吐量的分布式发布订阅消息系统，
它可以处理消费者规模的网站中的所有动作流数据。
Kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息。





Zookeeper集群：是一个为Kafka的分布式应用提供一致性服务的软件，
提供的功能包括：配置维护、域名服务、分布式同步、组服务等。
Zookeeper可以实现封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。





Flume：用于收集数据到Kafka。
Flume的意义在于：
当收集数据的速度超过将写入数据的时候，也就是当收集信息遇到峰值时，
这时候收集的信息非常大，甚至超过了系统的写入数据能力，
这时候，Flume会在数据生产者和数据收容器间做出调整，保证其能够在两者之间提供平稳的数据。





采用Flume收集智能设备、传感器、原生日志等数据源实时产生的数据，
并将实时数据推送至Kafka消息队列中，继而由Storm在线实时处理。
最后，根据业务应用要求，将数据存储在Redis、MySQL、MongoDB等媒介。

同时，由Zookeeper集群管理，这样即使Kafka宕机重启后也能找到上次的消费记录，
接着从上次宕机点继续从Kafka的Broker中进行消费。
但是由于存在先消费后记录日志或者先记录后消费的非原子操作，
如果出现刚好消费完一条消息并还没将信息记录到Zookeeper的时候就宕机的类似问题，
或多或少都会存在少量数据丢失或重复消费的问题, 
其中一个解决方案就是Kafka的Broker和Zookeeper都部署在同一台机子上。
接下来就是使用用户定义好的Storm Topology去进行数据的分析并输出到Redis缓存数据库中
(也可以进行持久化)。
之所以在Flume和Storm中间加入一层Kafka消息系统，就是因为在高并发的条件下, 数据会井喷式增长，
如果Storm的消费速度(Storm的实时计算能力那是最快之一,
但是也有例外, 而且据说现在Twitter的开源实时计算框架Heron比Storm还要快)慢于数据的产生速度，
加上Flume自身的局限性，必然会导致大量数据滞后并丢失，
所以加了Kafka消息系统作为数据缓冲区，
而且Kafka是基于log File的消息系统，也就是说消息能够持久化在硬盘中，
再加上其充分利用Linux的I/O特性,提供了可观的吞吐量。
架构中使用Redis作为数据库也是因为在实时的环境下，Redis具有很高的读写速度。




